{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f50ef734",
   "metadata": {
    "cellId": "3jkz1jkvqg2gy6kav3rfav"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from sentencepiece import SentencePieceTrainer, SentencePieceProcessor\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Union, List, Tuple\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# input_dir = '/kaggle/input/bdz-jsons/'\n",
    "# working_dir = '/kaggle/working/'\n",
    "input_dir = ''\n",
    "working_dir = ''\n",
    "\n",
    "file_names = os.listdir(input_dir)\n",
    "with open('all_texts.txt', 'w') as out:\n",
    "#     for i in tqdm(range(30)):\n",
    "#     for i in tqdm(range(len(file_names))):\n",
    "    for i in tqdm(range(len(file_names))):\n",
    "        file_name = file_names[i]\n",
    "        with open(input_dir + file_name, 'r') as input:\n",
    "            data = json.load(input)\n",
    "        for tex in data:\n",
    "            text = tex['story'].replace('\\n', ' ').replace('\\\\n', ' ')\n",
    "            if len(text):\n",
    "                print(text, file=out, end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f9b8dd14",
   "metadata": {
    "cellId": "h7qm73kpv7it6ngpbgewx"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data_file: str, train: bool = True, sp_model_prefix: str = None,\n",
    "                 vocab_size: int = 2000, normalization_rule_name: str = 'nmt_nfkc_cf',\n",
    "                 model_type: str = 'bpe', max_length: int = 256):\n",
    "        if not os.path.isfile(sp_model_prefix + '.model'):\n",
    "            SentencePieceTrainer.train(\n",
    "                input=data_file, vocab_size=vocab_size,\n",
    "                model_type=model_type, model_prefix=sp_model_prefix,\n",
    "                normalization_rule_name=normalization_rule_name,\n",
    "                pad_id=3\n",
    "            )\n",
    "\n",
    "        self.sp_model = SentencePieceProcessor(model_file=sp_model_prefix + '.model')\n",
    "\n",
    "        with open(data_file) as file:\n",
    "            texts = file.readlines()\n",
    "\n",
    "        self.texts = texts\n",
    "\n",
    "        self.pad_id, self.unk_id, self.bos_id, self.eos_id = \\\n",
    "            self.sp_model.pad_id(), self.sp_model.unk_id(), \\\n",
    "            self.sp_model.bos_id(), self.sp_model.eos_id()\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.vocab_size = self.sp_model.vocab_size()\n",
    "\n",
    "    def text2ids(self, texts: Union[str, List[str]]) -> Union[List[int], List[List[int]]]:\n",
    "        return self.sp_model.encode(texts)\n",
    "\n",
    "    def ids2text(self, ids: Union[torch.Tensor, List[int], List[List[int]]]) -> Union[str, List[str]]:\n",
    "        if torch.is_tensor(ids):\n",
    "            assert len(ids.shape) <= 2, 'Expected tensor of shape (length, ) or (batch_size, length)'\n",
    "            ids = ids.cpu().tolist()\n",
    "\n",
    "        return self.sp_model.decode(ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item: int) -> Tuple[torch.Tensor, int]:\n",
    "        ids = self.text2ids(self.texts[item].strip())\n",
    "        encoded = ids[:min(len(ids), self.max_length - 2)]\n",
    "        encoded = [self.bos_id] + encoded + [self.eos_id]\n",
    "        padded = torch.full((self.max_length,), self.pad_id, dtype=torch.int64)\n",
    "        padded[:len(encoded)] = torch.tensor(encoded)\n",
    "        return padded, len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "47ce97cc",
   "metadata": {
    "cellId": "16c9ykgzmg3ybhb0zv90o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3d8486af",
   "metadata": {
    "cellId": "d487nk9cb64f884hhk2typ"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import math\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.distributions import Categorical\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, : x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, activation=\"gelu\", batch_first=True)\n",
    "\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.embedding = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(d_model, ntoken)\n",
    "        self.dummy_param = nn.Parameter(torch.empty(0))\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(\n",
    "            self, src: Tensor, src_mask: Tensor = None, src_key_padding_mask: Tensor = None\n",
    "    ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape ``[batch_size, seq_len]``\n",
    "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape ``[batch_size, seq_len, ntoken]``\n",
    "        \"\"\"\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        if src_mask is None:\n",
    "            \"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n",
    "            Unmasked positions are filled with float(0.0).\n",
    "            \"\"\"\n",
    "            src_mask = (nn.Transformer.generate_square_subsequent_mask(src.shape[1]).to(device).isinf())\n",
    "            \n",
    "        output = self.transformer_encoder(src,mask=src_mask,)\n",
    "        output = self.linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5e7ef480",
   "metadata": {
    "cellId": "7vkbuq8t4pqykfbtduv5m9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec1a62ec",
   "metadata": {
    "cellId": "sy14bqy5v9nbhs7622fh8t"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "dataset = TextDataset(data_file=\"all_texts.txt\", sp_model_prefix=\"bpe\", vocab_size=5000, max_length=256)\n",
    "train_loader = DataLoader(dataset, batch_size=768, shuffle=True, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a70f29ec",
   "metadata": {
    "cellId": "6ilo2bypq6k6zs4io96z0g"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model = Model(ntoken=dataset.sp_model.vocab_size(), d_model=256, nhead=4, \n",
    "              d_hid=256, nlayers=4,)\n",
    "model.to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=dataset.sp_model.pad_id())\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=5e-4,\n",
    "    betas=(0.9, 0.95),\n",
    "    weight_decay=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fa077bac",
   "metadata": {
    "cellId": "t4a71sw26rpb47gtvzp17"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcae1be8521a4e628d5acaa13a418d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3304779a8035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtrain_losses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loader' is not defined"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "num_epochs = 4\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    for indices, lengths in tqdm(train_loader):\n",
    "        tokens = indices[:, :lengths.max()].to(device)\n",
    "        optimizer.zero_grad()\n",
    "#         with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16): \n",
    "        logits = model(tokens[:, :-1])\n",
    "        loss = criterion(logits.transpose(1, 2), tokens[:, 1:])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * tokens.shape[0]\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    print('Train loss =', train_loss, 'on ep :', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8667d43d",
   "metadata": {
    "cellId": "zqbub6ebd2870syv0o2s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss = 1.8136762476889643 on ep : 1\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "train_loss /= len(train_loader.dataset)\n",
    "\n",
    "print('Train loss =', train_loss, 'on ep :', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eec9fc",
   "metadata": {
    "cellId": "shytzqa75qp4jhmj24xrbp"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Далее код не сохранялся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1149e",
   "metadata": {
    "cellId": "jossv8rbul7e970r1xa14"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2-xl')\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f239ffc",
   "metadata": {
    "cellId": "1que7pe7zwxwhs6yn92lii"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def arr_(dict_):\n",
    "    ans = []\n",
    "    for el in dict_:\n",
    "        ans.append(el['generated_text'])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef36c2",
   "metadata": {
    "cellId": "zt7mo7ul8rikjpuf3p4tmo"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "arr_(generator(\"Once upon a time, in an ancient house, there lived a girl named Lily. She loved to decorate her room with pretty things. One day, she found a big box in the attic. She opened it and saw many shiny decorations. Lily was very happy and decided to use them in her room.As Lily was decorating her room, the sky outside became dark. There was a loud\",\n",
    "               max_length=500,\n",
    "               num_return_sequences=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7378284e",
   "metadata": {
    "cellId": "els3764pb6ovmvk1ad5xdi"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def inference(model, tokenizer, max_length=20, rep = 3, prefix=''):\n",
    "    model.eval()\n",
    "    anses = []\n",
    "    for _ in range(rep):\n",
    "        sent_tokens = torch.tensor([[tokenizer.bos_id()] + tokenizer.encode(prefix)])\n",
    "        sent_tokens = sent_tokens.to(device)\n",
    "        for _ in range(max_length):\n",
    "            logits = model(sent_tokens)\n",
    "            token = Categorical(logits=logits[0, -1]).sample()\n",
    "            token = token.unsqueeze(0).unsqueeze(0)\n",
    "            if token.item() == tokenizer.eos_id():\n",
    "                break\n",
    "            sent_tokens = torch.cat([sent_tokens, token], axis=1)\n",
    "        ans = tokenizer.decode(sent_tokens.squeeze().tolist())\n",
    "        anses.append(ans)\n",
    "    return anses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "inference(model, dataset.sp_model, max_length=15, rep = 3, prefix=\"Boy played with his dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "7411e33a-a531-481e-b1c3-526854eb1697",
  "notebookPath": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
